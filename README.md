Implementation of the Archive Multi-Agent Inverse Reinforcement Learning (AMAIRL) [^1] and Multi-Agent Adversarial Inverse Reinforcement Learning (MA-AIRL)[^2] algorithms, used in the research for the master thesis titled  "Cooperative Multi-Agent Inverse Reinforcement Learning: Towards Better Modelling of Cooperative Behavior".

For the MA_AIRL algorithm the original repository [^3] was adapted to the needs of this project while for the MaxEnt algorithm and the AMAIRL implementation the ideas present in the repository [^4] were used as a starting point. 
The AMAIRL method was implemented from scratch while the other two algorithms were adapted to the environments used in this research.

[^3]:  https://github.com/ermongroup/MA-AIRL
[^4]:  https://github.com/qzed/irl-maxent
[^1]: Y. Fukumoto, M. Tadokoro and K. Takadama, "Cooperative Multi-agent Inverse Reinforcement Learning Based on Selfish Expert and its Behavior Archives," 2020 IEEE Symposium Series on Computational Intelligence (SSCI), Canberra, ACT, Australia, 2020, pp. 2202-2209, doi: 10.1109/SSCI47803.2020.9308491.
[^2]: Yu, L., Song, J. &amp; Ermon, S.. (2019). Multi-Agent Adversarial Inverse Reinforcement Learning. <i>Proceedings of the 36th International Conference on Machine Learning</i>, in <i>Proceedings of Machine Learning Research</i> 97:7194-7201 Available from https://proceedings.mlr.press/v97/yu19e.html.



 
